{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Review of Models for Predicting Financial Market Crashes Using Market Data\n",
    "## COMP 451: Final Project - Code, experiments and plots\n",
    "---\n",
    "\n",
    "\n",
    "Written by\n",
    "- Adrien BÃ©langer  \n",
    "- Inigo Torres  \n",
    "- Ping-Chieh Tu  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf # to get our data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler # to normalize our classes\n",
    "from sklearn.model_selection import train_test_split # from tutorial code\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix # needed for plotting\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model # sequential model for RNN\n",
    "from tensorflow.keras.layers import (Input, Dense, Dropout, LayerNormalization,\n",
    "                                     MultiHeadAttention, Flatten, Add, LSTM) # layers dense and long short term memory for RNN\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^GSPC S&P 500 ^GSPC (24351, 7) 1927-12-30 00:00:00-05:00 2024-12-06 00:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "dfs = {} # Store all the data for our tickers, even though for now its just SP500\n",
    "tickers = ['^GSPC',] # Ticker (identifier) for the SP500, which is arguably the most influential, we start with just this\n",
    "\n",
    "# Got this code from https://www.kaggle.com/code/xxxxyyyy80008/predict-stock-market-crashes \n",
    "for ticker in tickers:\n",
    "    cur_data = yf.Ticker(ticker)\n",
    "    hist = cur_data.history(period=\"max\")\n",
    "    print(ticker, cur_data.info['shortName'], ticker, hist.shape, hist.index.min(), hist.index.max())\n",
    "    dfs[ticker] = hist\n",
    "\n",
    "# Preprocessign Functions:\n",
    "# Calculates how much the price has gone down from its highest point, labeling those with a 0.005 quantile as crashes as per directive 1\n",
    "# NOTE: got help from chatgpt for this function to find .pct_change, .cummax and .quantile\n",
    "def calculate_drawdown_and_label(data, quantile_threshold=0.005):\n",
    "\n",
    "    data['daily_return'] = data['Close'].pct_change()\n",
    "\n",
    "    data['drawdown'] = data['Close'] / data['Close'].cummax() - 1\n",
    "\n",
    "    crash_threshold = data['drawdown'].quantile(quantile_threshold)\n",
    "\n",
    "    data['crash_label'] = (data['drawdown'] < crash_threshold).astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "## Make the data we targetted the target (nice), we try to predict the market crashes 3 days in advance so shift_days = 3\n",
    "def prepare_target(data, shift_days=3):\n",
    "    data['target'] = (data['crash_label']).astype(int).shift(-shift_days) # complicated line that basically takes our data with crash label, turns the bools into an int, then shift the values by 3 days to predict in advance, since we want to predict 3 days in advance\n",
    "    return data\n",
    "\n",
    "\n",
    "# Database done\n",
    "# Prepare data\n",
    "def preprocess_data(data, sequence_length=15): # data is our data we\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))  # Normalize our features between 0 and 1 to make sure its all the same, since prices and dropdown are very much not all on scale.\n",
    "    scaled_data = scaler.fit_transform(data[['Close', 'daily_return', 'drawdown']].dropna()) # our simple features we defined before + the ones from hist, scale them and create. .dropna removes the rows that have features which are nan i.e. rows with missing features\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(scaled_data) - sequence_length): # process data by sequences of days to learn. This is a window, so we go from one day to the next. for example, if we have day 1 to day 15 on iteration i, at iteration i + 1 we have day 2 to 16. this window is a single datapoint within a single minibatch.\n",
    "        days = scaled_data[i:i+sequence_length] # get the sequence of 15 days\n",
    "        X.append(days) # add to x the data as sequences of 15 days\n",
    "        y.append(data['target'].iloc[i + sequence_length]) # this is the target. It adds the value of the next sequence as the target, so we can predict future crashes\n",
    "\n",
    "    X = np.array(X) # turn into array for processing\n",
    "    y = np.array(y)\n",
    "     \n",
    "    \n",
    "    y = y[~np.isnan(y)]  # remove nan of the last few data points, since we shift by 3 days the last few points. i.e. for day 1, the target is day 4 for three days. so at the end of the seuquence wed get 3 empty datapoints. \n",
    "    X = X[:len(y)]  # cut those data points which had no y, i.e. the last few days\n",
    "    return X, y, scaler # return the scaler function to make sure when we process the test data and validation data, we can process the data before feeding it into our model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN model from keras.\n",
    "# NOTE: chtgpt helped me find the return_sequences parameter and input_shape parameters. it also helped me find the model.compile names of the specific functions (is it binary_cross_entropy or binary_crossentropy)\n",
    "def rnn_model(input): # by giv\n",
    "    model = Sequential() # choose the RNN (i.e. sequential) so we can stack models\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input)) # first lstm layer with 50 nodes (arbitrary), we return sequences not the final output since were passing it to another lstm layer\n",
    "    model.add(LSTM(units=50)) # second LSTM layer, this time we do return the final output\n",
    "    model.add(Dense(units=1, activation='sigmoid'))  #dense layer with 1 node to classify binary. because were classifying binarily whether theres a crash, then we use sigmoid to just classify if thres a crash or not\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compile our model with an adam optimizer to adjust our learning rate when were getting closer.. might need to try sgd. binary cross entropy since were binary. accuracy to track during trainign and testing.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(sequence_length, d_model):\n",
    "    position = np.arange(sequence_length)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "    pe = np.zeros((sequence_length, d_model))\n",
    "    pe[:, 0::2] = np.sin(position * div_term)\n",
    "    pe[:, 1::2] = np.cos(position * div_term)\n",
    "    pe = pe[np.newaxis, ...]\n",
    "    return tf.cast(pe, dtype=tf.float32)\n",
    "\n",
    "def transformer_model(input_shape, num_heads=2, embed_dim=32, ff_dim=64):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    x = Dense(embed_dim)(x)\n",
    "\n",
    "    sequence_length = input_shape[0]\n",
    "    positional_encoding_layer = positional_encoding(sequence_length, embed_dim)\n",
    "    x = x + positional_encoding_layer\n",
    "\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads)(x, x)\n",
    "    attention_output = Add()([attention_output, x])\n",
    "    attention_output = LayerNormalization(epsilon=1e-6)(attention_output)\n",
    "\n",
    "    ffn_output = Dense(ff_dim, activation='relu')(attention_output)\n",
    "    ffn_output = Dense(embed_dim)(ffn_output)\n",
    "    ffn_output = Add()([ffn_output, attention_output])\n",
    "    ffn_output = LayerNormalization(epsilon=1e-6)(ffn_output)\n",
    "\n",
    "    flatten = Flatten()(ffn_output)\n",
    "    outputs = Dense(1, activation='sigmoid')(flatten)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_arima(X_test, sequence_length, shift_days, threshold=0.005, p=5, d=1, q=0):\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "       # make sure we ge tonly the sequence length\n",
    "        if i + sequence_length > len(X_test):\n",
    "            break  \n",
    "        \n",
    "        train_sequence = X_test[i, :, 0]  \n",
    "\n",
    "        model = ARIMA(train_sequence, order=(p, q, d))  \n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # clauclate the forecast on the next 3 days\n",
    "        forecast = model_fit.forecast(steps=shift_days)\n",
    "\n",
    "        # check the drawdown: NOTE: Got help\n",
    "        forecast_drawdown = (np.array(forecast) / max(train_sequence) - 1)\n",
    "        isit_crash = False\n",
    "        for dd in forecast_drawdown: # check if anything is lower than the threshold\n",
    "            if (dd < -threshold):\n",
    "                isit_crash = True\n",
    "                break\n",
    "        \n",
    "        predictions.append(1 if isit_crash == 1 else 0) # make it a crash if its 0\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA - Stationarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: 7.406940\n",
      "ADF p-value: 1.000000\n",
      "KPSS result: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qn/vrv88lcd66jdmpx64t33xst80000gn/T/ipykernel_99703/2001048645.py:11: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is smaller than the p-value returned.\n",
      "\n",
      "  kpss_result = kpss(df['Close'])\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "df = dfs['^GSPC']\n",
    "\n",
    "adf_test = adfuller(df['Close'])\n",
    "# Output the results\n",
    "print('ADF Statistic: %f' % adf_test[0])\n",
    "print('ADF p-value: %f' % adf_test[1])\n",
    "\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "kpss_result = kpss(df['Close'])\n",
    "print(f'KPSS result: {kpss_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ADF test and KPSS test result, our data is non-stationary, therefore the difference term $d$ is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA - PACF and ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "df = dfs['^GSPC']\n",
    "plot_pacf(df['Close'], lags=7)\n",
    "plot_acf(df['Close'], lags=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From PACF, we can choose either $p = 0$ or $p=1$. From ACF, it is hard to tell what should be the degree of $q$, so we will do grid search before each experiment do ensure that we do get the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditions:**\n",
    "\n",
    "- Sliding window: 30 days\n",
    "\n",
    "- Shift days: 14 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 30 # how large our window is\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 20\n",
    "SHIFT_DAYS = 14 # how far ahead we want to predict market crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the data\n",
    "for ticker, data in dfs.items():\n",
    "    data = calculate_drawdown_and_label(data) # get the drawdown for our data\n",
    "    data = prepare_target(data, SHIFT_DAYS)\n",
    "    dfs[ticker] = data\n",
    "\n",
    "# now we process our data, here we do as if we had multiple tickers, in case we add more later\n",
    "sequence_length = SEQUENCE_LENGTH # hyperparameter for the length of the window. 15 is completely arbirtrary here, need to adjust to get better or worst results.\n",
    "X = {} # data of all the tickers\n",
    "y = {} # labels of all the tickers\n",
    "scalers = {} # scalers of all the tickers\n",
    "for ticker, data in dfs.items(): #iterate through each ticker, datapoint and the dataframes (dfs) we got from yf, and preprocess them then add them to the dictionnary\n",
    "    X[ticker], y[ticker], scalers[ticker] = preprocess_data(data, sequence_length=sequence_length) \n",
    "\n",
    "# Combine data from all our tickers, joining them on axis 0 i.e. we want to concatenate all the rows together\n",
    "X_all = np.concatenate([X[ticker] for ticker in X], axis=0)\n",
    "y_all = np.concatenate([y[ticker] for ticker in y], axis=0) # same thing for labels\n",
    "\n",
    "# give 20% as test size, 80% for our training data. this functino was found in the tutorial ipynb\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=TEST_SIZE, random_state=42)\n",
    "# NOTE: chatgpt helped me for the input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) # recall X_train is (batch_size, sequence_length, 3 (for 3 features for now)), here we give the batch size and the sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_1_rnn_trained_model = rnn_model(input_shape) # build our model with our function from before\n",
    "\n",
    "exp_1_rnn_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test)) # train our model. relatively large batch size considering we dont have much data, but im getting pretty good accuracy. we use our test data for validation, arguably not great but were not using for early stopping so I guess its ok\n",
    "\n",
    "##### GET ACCURACY AND CONFUSION MATRIX #####\n",
    "exp_1_rnn_predictions_as_probabilities = exp_1_rnn_trained_model.predict(X_test)\n",
    "exp_1_rnn_predictions_as_classes = (exp_1_rnn_predictions_as_probabilities > 0.5).astype(int) # make our predictions binary, a simple scaler that puts values higher than 0.5 to 1 and lower 0. astypeint to return 0 and 1 instead of true false array.\n",
    "exp_1_rnn_accuracy = accuracy_score(y_test, exp_1_rnn_predictions_as_classes) # calculate our accuracy\n",
    "\n",
    "exp_1_rnn_confusion_matrix_var = confusion_matrix(y_test, exp_1_rnn_predictions_as_classes) # plot the confusion matrix\n",
    "#############################################\n",
    "\n",
    "\n",
    "### FINAL ACCURACY\n",
    "print(f\"Test Accuracy: {exp_1_rnn_accuracy}\") # print our final accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m exp_1_transformer_trained_model \u001b[38;5;241m=\u001b[39m transformer_model(\u001b[43minput_shape\u001b[49m)\n",
      "\u001b[1;32m      2\u001b[0m exp_1_transformer_trained_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "exp_1_transformer_trained_model = transformer_model(input_shape)\n",
    "exp_1_transformer_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
    "\n",
    "exp_1_transformer_predictions_as_probabilities = exp_1_transformer_trained_model.predict(X_test)\n",
    "exp_1_transformer_predictions_as_classes = (exp_1_transformer_predictions_as_probabilities > 0.5).astype(int)\n",
    "\n",
    "exp_1_transformer_accuracy = accuracy_score(y_test, exp_1_transformer_predictions_as_classes)\n",
    "exp_1_transformer_confusion_matrix_var = confusion_matrix(y_test, exp_1_transformer_predictions_as_classes)\n",
    "\n",
    "print(f\"Transformers EXP 1 Accuracy: {exp_1_transformer_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Grid Search\n",
    "\n",
    "p, d, q = 0, 1, 0\n",
    "best_hyperparameter = (0, 1, 0)\n",
    "best_accuracy = 0\n",
    "\n",
    "try: \n",
    "    for p in range(3): \n",
    "        for d in range(1, 3):  \n",
    "            for q in range(6):  \n",
    "                try:\n",
    "                    print(f'Hyperparameter: p={p}, d={d}, q={q}')\n",
    "                    exp_1_predictions = forecast_arima(\n",
    "                        X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=p, d=d, q=q\n",
    "                    )\n",
    "                    exp_1_predictions_as_classes = np.array(exp_1_predictions[:len(y_test)])\n",
    "                    accuracy = accuracy_score(y_test[:len(exp_1_predictions_as_classes)], exp_1_predictions_as_classes)\n",
    "                    print(f'Accuracy: {accuracy}')\n",
    "                    \n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_hyperparameter = (p, d, q)\n",
    "                        best_accuracy = accuracy\n",
    "\n",
    "                except np.linalg.LinAlgError:  \n",
    "                    pass\n",
    "                    print(f'Failed to fit ARIMA with p={p}, d={d}, q={q}')\n",
    "                except Exception as e:  # Catch other unexpected errors\n",
    "                    print(f'Error with p={p}, d={d}, q={q}: {str(e)}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")\n",
    "\n",
    "print(f'\\nBest hyperparameter: {best_hyperparameter}')\n",
    "print(f'Best Accuracy: {best_accuracy}')\n",
    "\n",
    "\n",
    "#### Fitting the model with the best hyper parameters\n",
    "\n",
    "exp_1_arima_predictions = forecast_arima(X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=best_hyperparameter[0], d=best_hyperparameter[1], q=best_hyperparameter[2])\n",
    "exp_1_arima_predictions_as_classes = np.array(exp_1_arima_predictions[:len(y_test)])\n",
    "\n",
    "exp_1_arima_accuracy = accuracy_score(y_test[:len(exp_1_arima_predictions)], exp_1_arima_predictions_as_classes)\n",
    "print(f'ARIMA Accuracy on EXP 1: {exp_1_arima_accuracy}')\n",
    "\n",
    "exp_1_arima_confusion_matrix_var = confusion_matrix(y_test[:len(exp_1_arima_predictions)], exp_1_arima_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN\n",
    "exp_1_rnn_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_1_rnn_predicted_crashes = int((exp_1_rnn_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_1_rnn_predicted_correctly = int(exp_1_rnn_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_1_rnn_missed_crashes = int(exp_1_rnn_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_1_rnn_predicted_when_there_wasnt = int(exp_1_rnn_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n",
    "\n",
    "## Transformers\n",
    "exp_1_transformer_real_crashes = int(sum(y_test == 1))\n",
    "exp_1_transformer_predicted_crashes = int((exp_1_transformer_predictions_as_classes == 1).sum())\n",
    "exp_1_transformer_predicted_correctly = int(exp_1_transformer_confusion_matrix_var[1, 1])\n",
    "exp_1_transformer_missed_crashes = int(exp_1_transformer_confusion_matrix_var[1, 0])\n",
    "exp_1_transformer_predicted_when_there_wasnt = int(exp_1_transformer_confusion_matrix_var[0, 1])\n",
    "\n",
    "## ARIMA\n",
    "\n",
    "exp_1_arima_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_1_arima_predicted_crashes = int((exp_1_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_1_arima_predicted_correctly = int(exp_1_arima_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_1_arima_missed_crashes = int(exp_1_arima_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_1_arima_predicted_when_there_wasnt = int(exp_1_arima_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# RNN data\n",
    "rnn_values = [\n",
    "    exp_1_rnn_real_crashes,\n",
    "    exp_1_rnn_predicted_crashes,\n",
    "    exp_1_rnn_predicted_correctly,\n",
    "    exp_1_rnn_missed_crashes,\n",
    "    exp_1_rnn_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# Transformer data\n",
    "transformer_values = [\n",
    "    exp_1_transformer_real_crashes,\n",
    "    exp_1_transformer_predicted_crashes,\n",
    "    exp_1_transformer_predicted_correctly,\n",
    "    exp_1_transformer_missed_crashes,\n",
    "    exp_1_transformer_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# ARIMA data\n",
    "arima_values = [\n",
    "    exp_1_arima_real_crashes,\n",
    "    exp_1_arima_predicted_crashes,\n",
    "    exp_1_arima_predicted_correctly,\n",
    "    exp_1_arima_missed_crashes,\n",
    "    exp_1_arima_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    \"Actual Crashes\",\n",
    "    \"Predicted Crashes\",\n",
    "    \"Correctly Predicted Crashes\",\n",
    "    \"Missed Crashes\",\n",
    "    \"False Alarms\"\n",
    "]\n",
    "\n",
    "x = np.arange(len(categories)) \n",
    "width = 0.25 \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "bars_rnn = ax.bar(x - width, rnn_values, width, label='RNN', color='orange')\n",
    "bars_transformer = ax.bar(x, transformer_values, width, label='Transformers', color='skyblue')\n",
    "bars_arima = ax.bar(x + width, arima_values, width, label='ARIMA', color='green')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Number of Crashes')\n",
    "ax.set_title('Performance Comparison: RNN, Transformers, and ARIMA')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "add_labels(bars_rnn)\n",
    "add_labels(bars_transformer)\n",
    "add_labels(bars_arima)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditions:**\n",
    "\n",
    "- Sliding window: 14 days\n",
    "\n",
    "- Shift days: 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 14 # how large our window is\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 20\n",
    "SHIFT_DAYS = 7 # how far ahead we want to predict market crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the data\n",
    "for ticker, data in dfs.items():\n",
    "    data = calculate_drawdown_and_label(data) # get the drawdown for our data\n",
    "    data = prepare_target(data, SHIFT_DAYS)\n",
    "    dfs[ticker] = data\n",
    "\n",
    "# now we process our data, here we do as if we had multiple tickers, in case we add more later\n",
    "sequence_length = SEQUENCE_LENGTH # hyperparameter for the length of the window. 15 is completely arbirtrary here, need to adjust to get better or worst results.\n",
    "X = {} # data of all the tickers\n",
    "y = {} # labels of all the tickers\n",
    "scalers = {} # scalers of all the tickers\n",
    "for ticker, data in dfs.items(): #iterate through each ticker, datapoint and the dataframes (dfs) we got from yf, and preprocess them then add them to the dictionnary\n",
    "    X[ticker], y[ticker], scalers[ticker] = preprocess_data(data, sequence_length=sequence_length) \n",
    "\n",
    "# Combine data from all our tickers, joining them on axis 0 i.e. we want to concatenate all the rows together\n",
    "X_all = np.concatenate([X[ticker] for ticker in X], axis=0)\n",
    "y_all = np.concatenate([y[ticker] for ticker in y], axis=0) # same thing for labels\n",
    "\n",
    "# give 20% as test size, 80% for our training data. this functino was found in the tutorial ipynb\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=TEST_SIZE, random_state=42)\n",
    "# NOTE: chatgpt helped me for the input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) # recall X_train is (batch_size, sequence_length, 3 (for 3 features for now)), here we give the batch size and the sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_2_rnn_trained_model = rnn_model(input_shape) # build our model with our function from before\n",
    "\n",
    "exp_2_rnn_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test)) # train our model. relatively large batch size considering we dont have much data, but im getting pretty good accuracy. we use our test data for validation, arguably not great but were not using for early stopping so I guess its ok\n",
    "\n",
    "##### GET ACCURACY AND CONFUSION MATRIX #####\n",
    "exp_2_rnn_predictions_as_probabilities = exp_2_rnn_trained_model.predict(X_test)\n",
    "exp_2_rnn_predictions_as_classes = (exp_2_rnn_predictions_as_probabilities > 0.5).astype(int) # make our predictions binary, a simple scaler that puts values higher than 0.5 to 1 and lower 0. astypeint to return 0 and 1 instead of true false array.\n",
    "exp_2_rnn_accuracy = accuracy_score(y_test, exp_2_rnn_predictions_as_classes) # calculate our accuracy\n",
    "\n",
    "exp_2_rnn_confusion_matrix_var = confusion_matrix(y_test, exp_2_rnn_predictions_as_classes) # plot the confusion matrix\n",
    "#############################################\n",
    "\n",
    "\n",
    "### FINAL ACCURACY\n",
    "print(f\"Test Accuracy: {exp_2_rnn_accuracy}\") # print our final accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m exp_1_transformer_trained_model \u001b[38;5;241m=\u001b[39m transformer_model(\u001b[43minput_shape\u001b[49m)\n",
      "\u001b[1;32m      2\u001b[0m exp_1_transformer_trained_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "exp_2_transformer_trained_model = transformer_model(input_shape)\n",
    "exp_2_transformer_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
    "\n",
    "exp_2_transformer_predictions_as_probabilities = exp_2_transformer_trained_model.predict(X_test)\n",
    "exp_2_transformer_predictions_as_classes = (exp_2_transformer_predictions_as_probabilities > 0.5).astype(int)\n",
    "\n",
    "exp_2_transformer_accuracy = accuracy_score(y_test, exp_2_transformer_predictions_as_classes)\n",
    "exp_2_transformer_confusion_matrix_var = confusion_matrix(y_test, exp_2_transformer_predictions_as_classes)\n",
    "\n",
    "print(f\"Transformers EXP 1 Accuracy: {exp_2_transformer_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: p=0, d=1, q=0\n",
      "Unexpected error occurred: name 'np' is not defined\n",
      "\n",
      "Best hyperparameter: (0, 1, 0)\n",
      "Best Accuracy: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'forecast_arima' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#### Fitting the model with the best hyper parameters\u001b[39;00m\n",
      "\u001b[0;32m---> 40\u001b[0m exp_2_arima_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_arima\u001b[49m(X_test, sequence_length\u001b[38;5;241m=\u001b[39mSEQUENCE_LENGTH, shift_days\u001b[38;5;241m=\u001b[39mSHIFT_DAYS, p\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m0\u001b[39m], d\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m1\u001b[39m], q\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;32m     41\u001b[0m exp_2_arima_predictions_as_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(exp_2_arima_predictions[:\u001b[38;5;28mlen\u001b[39m(y_test)])\n",
      "\u001b[1;32m     43\u001b[0m exp_2_arima_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test[:\u001b[38;5;28mlen\u001b[39m(exp_2_arima_predictions)], exp_2_arima_predictions_as_classes)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forecast_arima' is not defined"
     ]
    }
   ],
   "source": [
    "###### Grid Search\n",
    "\n",
    "p, d, q = 0, 1, 0\n",
    "best_hyperparameter = (0, 1, 0)\n",
    "best_accuracy = 0\n",
    "\n",
    "try: \n",
    "    for p in range(3): \n",
    "        for d in range(1, 3):  \n",
    "            for q in range(6):  \n",
    "                try:\n",
    "                    print(f'Hyperparameter: p={p}, d={d}, q={q}')\n",
    "                    exp_2_predictions = forecast_arima(\n",
    "                        X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=p, d=d, q=q\n",
    "                    )\n",
    "                    exp_2_predictions_as_classes = np.array(exp_2_predictions[:len(y_test)])\n",
    "                    accuracy = accuracy_score(y_test[:len(exp_2_predictions_as_classes)], exp_2_predictions_as_classes)\n",
    "                    print(f'Accuracy: {accuracy}')\n",
    "                    \n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_hyperparameter = (p, d, q)\n",
    "                        best_accuracy = accuracy\n",
    "\n",
    "                except np.linalg.LinAlgError:  \n",
    "                    pass\n",
    "                    print(f'Failed to fit ARIMA with p={p}, d={d}, q={q}')\n",
    "                except Exception as e:  # Catch other unexpected errors\n",
    "                    print(f'Error with p={p}, d={d}, q={q}: {str(e)}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")\n",
    "\n",
    "print(f'\\nBest hyperparameter: {best_hyperparameter}')\n",
    "print(f'Best Accuracy: {best_accuracy}')\n",
    "\n",
    "\n",
    "#### Fitting the model with the best hyper parameters\n",
    "\n",
    "exp_2_arima_predictions = forecast_arima(X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=best_hyperparameter[0], d=best_hyperparameter[1], q=best_hyperparameter[2])\n",
    "exp_2_arima_predictions_as_classes = np.array(exp_2_arima_predictions[:len(y_test)])\n",
    "\n",
    "exp_2_arima_accuracy = accuracy_score(y_test[:len(exp_2_arima_predictions)], exp_2_arima_predictions_as_classes)\n",
    "print(f'ARIMA Accuracy on EXP 1: {exp_2_arima_accuracy}')\n",
    "\n",
    "exp_2_arima_confusion_matrix_var = confusion_matrix(y_test[:len(exp_2_arima_predictions)], exp_2_arima_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN\n",
    "exp_2_rnn_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_2_rnn_predicted_crashes = int((exp_2_rnn_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_2_rnn_predicted_correctly = int(exp_2_rnn_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_2_rnn_missed_crashes = int(exp_2_rnn_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_2_rnn_predicted_when_there_wasnt = int(exp_2_rnn_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n",
    "\n",
    "## Transformers\n",
    "exp_2_transformer_real_crashes = int(sum(y_test == 1))\n",
    "exp_2_transformer_predicted_crashes = int((exp_2_transformer_predictions_as_classes == 1).sum())\n",
    "exp_2_transformer_predicted_correctly = int(exp_2_transformer_confusion_matrix_var[1, 1])\n",
    "exp_2_transformer_missed_crashes = int(exp_2_transformer_confusion_matrix_var[1, 0])\n",
    "exp_2_transformer_predicted_when_there_wasnt = int(exp_2_transformer_confusion_matrix_var[0, 1])\n",
    "\n",
    "## ARIMA\n",
    "\n",
    "exp_2_arima_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_2_arima_predicted_crashes = int((exp_2_arima_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_2_arima_predicted_correctly = int(exp_2_arima_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_2_arima_missed_crashes = int(exp_2_arima_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_2_arima_predicted_when_there_wasnt = int(exp_2_arima_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# RNN data\n",
    "rnn_values = [\n",
    "    exp_2_rnn_real_crashes,\n",
    "    exp_2_rnn_predicted_crashes,\n",
    "    exp_2_rnn_predicted_correctly,\n",
    "    exp_2_rnn_missed_crashes,\n",
    "    exp_2_rnn_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# Transformer data\n",
    "transformer_values = [\n",
    "    exp_2_transformer_real_crashes,\n",
    "    exp_2_transformer_predicted_crashes,\n",
    "    exp_2_transformer_predicted_correctly,\n",
    "    exp_2_transformer_missed_crashes,\n",
    "    exp_2_transformer_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# ARIMA data\n",
    "arima_values = [\n",
    "    exp_2_arima_real_crashes,\n",
    "    exp_2_arima_predicted_crashes,\n",
    "    exp_2_arima_predicted_correctly,\n",
    "    exp_2_arima_missed_crashes,\n",
    "    exp_2_arima_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    \"Actual Crashes\",\n",
    "    \"Predicted Crashes\",\n",
    "    \"Correctly Predicted Crashes\",\n",
    "    \"Missed Crashes\",\n",
    "    \"False Alarms\"\n",
    "]\n",
    "\n",
    "\n",
    "x = np.arange(len(categories))  \n",
    "width = 0.25  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "bars_rnn = ax.bar(x - width, rnn_values, width, label='RNN', color='orange')\n",
    "bars_transformer = ax.bar(x, transformer_values, width, label='Transformers', color='skyblue')\n",
    "bars_arima = ax.bar(x + width, arima_values, width, label='ARIMA', color='green')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Number of Crashes')\n",
    "ax.set_title('Performance Comparison: RNN, Transformers, and ARIMA')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "add_labels(bars_rnn)\n",
    "add_labels(bars_transformer)\n",
    "add_labels(bars_arima)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditions:**\n",
    "\n",
    "- Sliding window: 7 days\n",
    "\n",
    "- Shift days: 3 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 7 # how large our window is\n",
    "TEST_SIZE = 0.2\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 20\n",
    "SHIFT_DAYS = 3 # how far ahead we want to predict market crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the data\n",
    "for ticker, data in dfs.items():\n",
    "    data = calculate_drawdown_and_label(data) # get the drawdown for our data\n",
    "    data = prepare_target(data, SHIFT_DAYS)\n",
    "    dfs[ticker] = data\n",
    "\n",
    "# now we process our data, here we do as if we had multiple tickers, in case we add more later\n",
    "sequence_length = SEQUENCE_LENGTH # hyperparameter for the length of the window. 15 is completely arbirtrary here, need to adjust to get better or worst results.\n",
    "X = {} # data of all the tickers\n",
    "y = {} # labels of all the tickers\n",
    "scalers = {} # scalers of all the tickers\n",
    "for ticker, data in dfs.items(): #iterate through each ticker, datapoint and the dataframes (dfs) we got from yf, and preprocess them then add them to the dictionnary\n",
    "    X[ticker], y[ticker], scalers[ticker] = preprocess_data(data, sequence_length=sequence_length) \n",
    "\n",
    "# Combine data from all our tickers, joining them on axis 0 i.e. we want to concatenate all the rows together\n",
    "X_all = np.concatenate([X[ticker] for ticker in X], axis=0)\n",
    "y_all = np.concatenate([y[ticker] for ticker in y], axis=0) # same thing for labels\n",
    "\n",
    "# give 20% as test size, 80% for our training data. this functino was found in the tutorial ipynb\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=TEST_SIZE, random_state=42)\n",
    "# NOTE: chatgpt helped me for the input_shape\n",
    "input_shape = (X_train.shape[1], X_train.shape[2]) # recall X_train is (batch_size, sequence_length, 3 (for 3 features for now)), here we give the batch size and the sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_3_rnn_trained_model = rnn_model(input_shape) # build our model with our function from before\n",
    "\n",
    "exp_3_rnn_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test)) # train our model. relatively large batch size considering we dont have much data, but im getting pretty good accuracy. we use our test data for validation, arguably not great but were not using for early stopping so I guess its ok\n",
    "\n",
    "##### GET ACCURACY AND CONFUSION MATRIX #####\n",
    "exp_3_rnn_predictions_as_probabilities = exp_3_rnn_trained_model.predict(X_test)\n",
    "exp_3_rnn_predictions_as_classes = (exp_3_rnn_predictions_as_probabilities > 0.5).astype(int) # make our predictions binary, a simple scaler that puts values higher than 0.5 to 1 and lower 0. astypeint to return 0 and 1 instead of true false array.\n",
    "exp_3_rnn_accuracy = accuracy_score(y_test, exp_3_rnn_predictions_as_classes) # calculate our accuracy\n",
    "\n",
    "exp_3_rnn_confusion_matrix_var = confusion_matrix(y_test, exp_3_rnn_predictions_as_classes) # plot the confusion matrix\n",
    "#############################################\n",
    "\n",
    "\n",
    "### FINAL ACCURACY\n",
    "print(f\"Test Accuracy: {exp_3_rnn_accuracy}\") # print our final accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m exp_1_transformer_trained_model \u001b[38;5;241m=\u001b[39m transformer_model(\u001b[43minput_shape\u001b[49m)\n",
      "\u001b[1;32m      2\u001b[0m exp_1_transformer_trained_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "exp_3_transformer_trained_model = transformer_model(input_shape)\n",
    "exp_3_transformer_trained_model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n",
    "\n",
    "exp_3_transformer_predictions_as_probabilities = exp_3_transformer_trained_model.predict(X_test)\n",
    "exp_3_transformer_predictions_as_classes = (exp_3_transformer_predictions_as_probabilities > 0.5).astype(int)\n",
    "\n",
    "exp_3_transformer_accuracy = accuracy_score(y_test, exp_3_transformer_predictions_as_classes)\n",
    "exp_3_transformer_confusion_matrix_var = confusion_matrix(y_test, exp_3_transformer_predictions_as_classes)\n",
    "\n",
    "print(f\"Transformers EXP 1 Accuracy: {exp_3_transformer_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: p=0, d=1, q=0\n",
      "Unexpected error occurred: name 'np' is not defined\n",
      "\n",
      "Best hyperparameter: (0, 1, 0)\n",
      "Best Accuracy: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'forecast_arima' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m\n",
      "\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#### Fitting the model with the best hyper parameters\u001b[39;00m\n",
      "\u001b[0;32m---> 40\u001b[0m exp_2_arima_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_arima\u001b[49m(X_test, sequence_length\u001b[38;5;241m=\u001b[39mSEQUENCE_LENGTH, shift_days\u001b[38;5;241m=\u001b[39mSHIFT_DAYS, p\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m0\u001b[39m], d\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m1\u001b[39m], q\u001b[38;5;241m=\u001b[39mbest_hyperparameter[\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[1;32m     41\u001b[0m exp_2_arima_predictions_as_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(exp_2_arima_predictions[:\u001b[38;5;28mlen\u001b[39m(y_test)])\n",
      "\u001b[1;32m     43\u001b[0m exp_2_arima_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test[:\u001b[38;5;28mlen\u001b[39m(exp_2_arima_predictions)], exp_2_arima_predictions_as_classes)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'forecast_arima' is not defined"
     ]
    }
   ],
   "source": [
    "###### Grid Search\n",
    "\n",
    "p, d, q = 0, 1, 0\n",
    "best_hyperparameter = (0, 1, 0)\n",
    "best_accuracy = 0\n",
    "\n",
    "try: \n",
    "    for p in range(3): \n",
    "        for d in range(1, 3):  \n",
    "            for q in range(6):  \n",
    "                try:\n",
    "                    print(f'Hyperparameter: p={p}, d={d}, q={q}')\n",
    "                    exp_3_predictions = forecast_arima(\n",
    "                        X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=p, d=d, q=q\n",
    "                    )\n",
    "                    exp_3_predictions_as_classes = np.array(exp_3_predictions[:len(y_test)])\n",
    "                    accuracy = accuracy_score(y_test[:len(exp_3_predictions_as_classes)], exp_3_predictions_as_classes)\n",
    "                    print(f'Accuracy: {accuracy}')\n",
    "                    \n",
    "                    \n",
    "                    if accuracy > best_accuracy:\n",
    "                        best_hyperparameter = (p, d, q)\n",
    "                        best_accuracy = accuracy\n",
    "\n",
    "                except np.linalg.LinAlgError:  \n",
    "                    pass\n",
    "                    print(f'Failed to fit ARIMA with p={p}, d={d}, q={q}')\n",
    "                except Exception as e:  # Catch other unexpected errors\n",
    "                    print(f'Error with p={p}, d={d}, q={q}: {str(e)}')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {str(e)}\")\n",
    "\n",
    "print(f'\\nBest hyperparameter: {best_hyperparameter}')\n",
    "print(f'Best Accuracy: {best_accuracy}')\n",
    "\n",
    "\n",
    "#### Fitting the model with the best hyper parameters\n",
    "\n",
    "exp_3_arima_predictions = forecast_arima(X_test, sequence_length=SEQUENCE_LENGTH, shift_days=SHIFT_DAYS, p=best_hyperparameter[0], d=best_hyperparameter[1], q=best_hyperparameter[2])\n",
    "exp_3_arima_predictions_as_classes = np.array(exp_3_arima_predictions[:len(y_test)])\n",
    "\n",
    "exp_3_arima_accuracy = accuracy_score(y_test[:len(exp_3_arima_predictions)], exp_3_arima_predictions_as_classes)\n",
    "print(f'ARIMA Accuracy on EXP 1: {exp_3_arima_accuracy}')\n",
    "\n",
    "exp_3_arima_confusion_matrix_var = confusion_matrix(y_test[:len(exp_3_arima_predictions)], exp_3_arima_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN\n",
    "exp_3_rnn_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_3_rnn_predicted_crashes = int((exp_3_rnn_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_3_rnn_predicted_correctly = int(exp_3_rnn_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_3_rnn_missed_crashes = int(exp_3_rnn_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_3_rnn_predicted_when_there_wasnt = int(exp_3_rnn_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n",
    "\n",
    "## Transformers\n",
    "exp_3_transformer_real_crashes = int(sum(y_test == 1))\n",
    "exp_3_transformer_predicted_crashes = int((exp_3_transformer_predictions_as_classes == 1).sum())\n",
    "exp_3_transformer_predicted_correctly = int(exp_3_transformer_confusion_matrix_var[1, 1])\n",
    "exp_3_transformer_missed_crashes = int(exp_3_transformer_confusion_matrix_var[1, 0])\n",
    "exp_3_transformer_predicted_when_there_wasnt = int(exp_3_transformer_confusion_matrix_var[0, 1])\n",
    "\n",
    "## ARIMA\n",
    "\n",
    "exp_3_arima_real_crashes = int(sum(y_test == 1)) # crashes in our test data\n",
    "exp_3_arima_predicted_crashes = int((exp_3_arima_predictions_as_classes == 1).sum()) # crashes are 1 in our predictions\n",
    "exp_3_arima_predicted_correctly = int(exp_3_arima_confusion_matrix_var[1, 1])  # tp in our confusion matrix\n",
    "exp_3_arima_missed_crashes = int(exp_3_arima_confusion_matrix_var[1, 0])  # fn in our confusion matrix\n",
    "exp_3_arima_predicted_when_there_wasnt = int(exp_3_arima_confusion_matrix_var[0, 1])  # fp in our confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# RNN data\n",
    "rnn_values = [\n",
    "    exp_3_rnn_real_crashes,\n",
    "    exp_3_rnn_predicted_crashes,\n",
    "    exp_3_rnn_predicted_correctly,\n",
    "    exp_3_rnn_missed_crashes,\n",
    "    exp_3_rnn_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# Transformer data\n",
    "transformer_values = [\n",
    "    exp_3_transformer_real_crashes,\n",
    "    exp_3_transformer_predicted_crashes,\n",
    "    exp_3_transformer_predicted_correctly,\n",
    "    exp_3_transformer_missed_crashes,\n",
    "    exp_3_transformer_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "# ARIMA data\n",
    "arima_values = [\n",
    "    exp_3_arima_real_crashes,\n",
    "    exp_3_arima_predicted_crashes,\n",
    "    exp_3_arima_predicted_correctly,\n",
    "    exp_3_arima_missed_crashes,\n",
    "    exp_3_arima_predicted_when_there_wasnt\n",
    "]\n",
    "\n",
    "categories = [\n",
    "    \"Actual Crashes\",\n",
    "    \"Predicted Crashes\",\n",
    "    \"Correctly Predicted Crashes\",\n",
    "    \"Missed Crashes\",\n",
    "    \"False Alarms\"\n",
    "]\n",
    "\n",
    "\n",
    "x = np.arange(len(categories))  \n",
    "width = 0.25  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "bars_rnn = ax.bar(x - width, rnn_values, width, label='RNN', color='orange')\n",
    "bars_transformer = ax.bar(x, transformer_values, width, label='Transformers', color='skyblue')\n",
    "bars_arima = ax.bar(x + width, arima_values, width, label='ARIMA', color='green')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Number of Crashes')\n",
    "ax.set_title('Performance Comparison: RNN, Transformers, and ARIMA')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  \n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "add_labels(bars_rnn)\n",
    "add_labels(bars_transformer)\n",
    "add_labels(bars_arima)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
