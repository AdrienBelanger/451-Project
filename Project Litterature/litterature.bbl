% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{Ahmed}{article}{}
      \name{author}{6}{}{%
        {{hash=72cd99778fd9ea6b75031c508db56a97}{%
           family={Ahmed},
           familyi={A\bibinitperiod},
           given={Sabeen},
           giveni={S\bibinitperiod}}}%
        {{hash=add92d282025e7794f8ac4571db94631}{%
           family={Nielsen},
           familyi={N\bibinitperiod},
           given={Ian\bibnamedelima E.},
           giveni={I\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=b04748051f6b40c351a774ded3ff99fe}{%
           family={Tripathi},
           familyi={T\bibinitperiod},
           given={Aakash},
           giveni={A\bibinitperiod}}}%
        {{hash=e4e18cdcfef94cb5440d518e388538ea}{%
           family={Siddiqui},
           familyi={S\bibinitperiod},
           given={Shamoon},
           giveni={S\bibinitperiod}}}%
        {{hash=6cebb0df8942ed27dd73f27cba8d7b22}{%
           family={Ramachandran},
           familyi={R\bibinitperiod},
           given={Ravi\bibnamedelima P.},
           giveni={R\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=95306ef8f0489755283f772b4bb3c4d1}{%
           family={Rasool},
           familyi={R\bibinitperiod},
           given={Ghulam},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{45541e05f899eaea5aeb65d28721e29b}
      \strng{fullhash}{8239993626b4bf6bcbea5b14f63768c2}
      \strng{bibnamehash}{8239993626b4bf6bcbea5b14f63768c2}
      \strng{authorbibnamehash}{8239993626b4bf6bcbea5b14f63768c2}
      \strng{authornamehash}{45541e05f899eaea5aeb65d28721e29b}
      \strng{authorfullhash}{8239993626b4bf6bcbea5b14f63768c2}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0278-081X}
      \field{journaltitle}{Circuits Syst. Signal Process.}
      \field{number}{12}
      \field{title}{Transformers in Time-Series Analysis: A Tutorial}
      \field{type}{Journal Article}
      \field{volume}{42}
      \field{year}{2023}
      \field{pages}{7433\bibrangedash 7466}
      \range{pages}{34}
      \verb{doi}
      \verb 10.1007/s00034-023-02454-8
      \endverb
      \verb{urlraw}
      \verb https://doi.org/10.1007/s00034-023-02454-8
      \endverb
      \verb{url}
      \verb https://doi.org/10.1007/s00034-023-02454-8
      \endverb
      \keyw{Positional encoding,Self-attention,Time-series,Transformer}
    \endentry
    \entry{ArunKumar}{article}{}
      \name{author}{5}{}{%
        {{hash=8bb57fd29d01a8f5f0bd19f9a6a0ade1}{%
           family={ArunKumar},
           familyi={A\bibinitperiod},
           given={K.\bibnamedelimi E.},
           giveni={K\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
        {{hash=4c713d8503601f13bc812bd2f257d295}{%
           family={Kalaga},
           familyi={K\bibinitperiod},
           given={Dinesh\bibnamedelima V.},
           giveni={D\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
        {{hash=fd8d400c0f7768f8085d4ec844c9eefc}{%
           family={Mohan\bibnamedelimb Sai\bibnamedelima Kumar},
           familyi={M\bibinitperiod\bibinitdelim S\bibinitperiod\bibinitdelim K\bibinitperiod},
           given={Ch},
           giveni={C\bibinitperiod}}}%
        {{hash=a8876b5bb10f7650214457d930a6bbfc}{%
           family={Kawaji},
           familyi={K\bibinitperiod},
           given={Masahiro},
           giveni={M\bibinitperiod}}}%
        {{hash=92fa705d03e3e8f923a32f2a081cd66e}{%
           family={Brenza},
           familyi={B\bibinitperiod},
           given={Timothy\bibnamedelima M.},
           giveni={T\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{f3a480b94df6c743142abcc27a5764c3}
      \strng{fullhash}{2f6694914f7ea3496a59356c7f30289d}
      \strng{bibnamehash}{2f6694914f7ea3496a59356c7f30289d}
      \strng{authorbibnamehash}{2f6694914f7ea3496a59356c7f30289d}
      \strng{authornamehash}{f3a480b94df6c743142abcc27a5764c3}
      \strng{authorfullhash}{2f6694914f7ea3496a59356c7f30289d}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Several machine learning and deep learning models were reported in the literature to forecast COVID-19 but there is no comprehensive report on the comparison between statistical models and deep learning models. The present work reports a comparative time-series analysis of deep learning techniques (Recurrent Neural Networks with GRU and LSTM cells) and statistical techniques (ARIMA and SARIMA) to forecast the country-wise cumulative confirmed, recovered, and deaths. The Gated Recurrent Units (GRU), Long Short-Term Memory (LSTM) cells based on Recurrent Neural Networks (RNN), ARIMA and SARIMA models were trained, tested, and optimized to forecast the trends of the COVID-19. We deployed python to optimize the parameters of ARIMA which include (p, d, q) representing autoregressive and moving average terms and parameters of SARIMA model include additional seasonal terms which are denoted by (P, D, Q). Similarly, for LSTM and GRU based RNN modelsâ€™ parameters (number of layers, hidden size, learning rate and number of epochs) are optimized by deploying PyTorch machine learning framework. The best model was chosen based on the lowest Mean Square Error (MSE) and Root Mean Squared Error (RMSE) values. For most of the time-series data of the countries, deep learning-based models LSTM and GRU outperformed statistical ARIMA and SARIMA models, with an RMSE values that are 40 folds less than that of the ARIMA models. But for some countries statistical (ARIMA, SARIMA) models outperformed deep learning models. Further, we emphasize the importance of various factors such as age, preventive measures and healthcare facilities etc. that play vital role on the rapid spread of COVID-19 pandemic.}
      \field{issn}{1110-0168}
      \field{journaltitle}{Alexandria Engineering Journal}
      \field{number}{10}
      \field{title}{Comparative analysis of Gated Recurrent Units (GRU), long Short-Term memory (LSTM) cells, autoregressive Integrated moving average (ARIMA), seasonal autoregressive Integrated moving average (SARIMA) for forecasting COVID-19 trends}
      \field{type}{Journal Article}
      \field{volume}{61}
      \field{year}{2022}
      \field{pages}{7585\bibrangedash 7603}
      \range{pages}{19}
      \verb{doi}
      \verb https://doi.org/10.1016/j.aej.2022.01.011
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1110016822000138
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1110016822000138
      \endverb
      \keyw{COVID-19 pandemic Gated Recurrent Units (GRUs) Long Short-Term Memory (LSTM) cells Recurrent Neural Networks (RNNs) Auto Regressive Integrated Moving Average (ARIMA) Seasonal Auto Regressive Integrated Moving Average (SARIMA)}
    \endentry
    \entry{Okpeke}{article}{}
      \name{author}{3}{}{%
        {{hash=81be828fc39f1a16375a3cfb2037dfba}{%
           family={Okpeke},
           familyi={O\bibinitperiod},
           given={Patience},
           giveni={P\bibinitperiod}}}%
        {{hash=38f1bd97df29410651eb9514ca57e0b1}{%
           family={Paul},
           familyi={P\bibinitperiod},
           given={Patience\bibnamedelima Okpeke},
           giveni={P\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
        {{hash=6fb8c9d61b88d4267bdd83692de95432}{%
           family={Iyelolu},
           familyi={I\bibinitperiod},
           given={Toluwalase\bibnamedelima Vanessa},
           giveni={T\bibinitperiod\bibinitdelim V\bibinitperiod}}}%
      }
      \strng{namehash}{080afa3cf8e4cc0afa34b9415557e88d}
      \strng{fullhash}{080afa3cf8e4cc0afa34b9415557e88d}
      \strng{bibnamehash}{080afa3cf8e4cc0afa34b9415557e88d}
      \strng{authorbibnamehash}{080afa3cf8e4cc0afa34b9415557e88d}
      \strng{authornamehash}{080afa3cf8e4cc0afa34b9415557e88d}
      \strng{authorfullhash}{080afa3cf8e4cc0afa34b9415557e88d}
      \field{sortinit}{2}
      \field{sortinithash}{8b555b3791beccb63322c22f3320aa9a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Open Access Research Journal of Science and Technology}
      \field{title}{Predicting stock market crashes with machine learning: A review and methodological proposal}
      \field{type}{Journal Article}
      \field{year}{2024}
    \endentry
    \entry{Mishkin}{report}{}
      \name{author}{2}{}{%
        {{hash=d53846c752552993eb4d540ed83a6a2f}{%
           family={Mishkin},
           familyi={M\bibinitperiod},
           given={Frederic\bibnamedelima S},
           giveni={F\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=4761f9e494164cda94e217532d4dbd4a}{%
           family={White},
           familyi={W\bibinitperiod},
           given={Eugene\bibnamedelima N},
           giveni={E\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \list{institution}{1}{%
        {National Bureau of Economic Research}%
      }
      \strng{namehash}{2dc84686cb8cd09b33ce13541b9625bf}
      \strng{fullhash}{2dc84686cb8cd09b33ce13541b9625bf}
      \strng{bibnamehash}{2dc84686cb8cd09b33ce13541b9625bf}
      \strng{authorbibnamehash}{2dc84686cb8cd09b33ce13541b9625bf}
      \strng{authornamehash}{2dc84686cb8cd09b33ce13541b9625bf}
      \strng{authorfullhash}{2dc84686cb8cd09b33ce13541b9625bf}
      \field{sortinit}{6}
      \field{sortinithash}{b33bc299efb3c36abec520a4c896a66d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper examines fifteen historical episodes of stock market crashes and their aftermath in the United States over the last one hundred years. Our basic conclusion from studying these episodes is that financial instability is the key problem facing monetary policy makers and not stock market crashes, even if they reflect the possible bursting of a bubble. With a focus on financial stability rather than the stock market, the response of central banks to stock market fluctuations is more likely to be optimal and maintain support for the independence of the central bank.}
      \field{month}{6}
      \field{number}{8992}
      \field{series}{Working Paper Series}
      \field{title}{U.S. Stock Market Crashes and Their Aftermath: Implications for Monetary Policy}
      \field{type}{Working Paper}
      \field{year}{2002}
      \verb{doi}
      \verb 10.3386/w8992
      \endverb
      \verb{urlraw}
      \verb http://www.nber.org/papers/w8992
      \endverb
      \verb{url}
      \verb http://www.nber.org/papers/w8992
      \endverb
    \endentry
    \entry{Schmidt}{article}{}
      \name{author}{1}{}{%
        {{hash=3c434db5f6f20ddfc1806a8d873a4748}{%
           family={Schmidt},
           familyi={S\bibinitperiod},
           given={Robin\bibnamedelima M.},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{3c434db5f6f20ddfc1806a8d873a4748}
      \strng{fullhash}{3c434db5f6f20ddfc1806a8d873a4748}
      \strng{bibnamehash}{3c434db5f6f20ddfc1806a8d873a4748}
      \strng{authorbibnamehash}{3c434db5f6f20ddfc1806a8d873a4748}
      \strng{authornamehash}{3c434db5f6f20ddfc1806a8d873a4748}
      \strng{authorfullhash}{3c434db5f6f20ddfc1806a8d873a4748}
      \field{sortinit}{7}
      \field{sortinithash}{108d0be1b1bee9773a1173443802c0a3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{CoRR}
      \field{title}{Recurrent Neural Networks (RNNs): A gentle Introduction and Overview}
      \field{type}{Journal Article}
      \field{volume}{abs/1912.05911}
      \field{year}{2019}
      \verb{urlraw}
      \verb http://arxiv.org/abs/1912.05911
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1912.05911
      \endverb
    \endentry
    \entry{Hansika}{article}{}
      \name{author}{3}{}{%
        {{hash=bcedb4c1d2a852d41022a05e63751bf9}{%
           family={Hewamalage},
           familyi={H\bibinitperiod},
           given={Hansika},
           giveni={H\bibinitperiod}}}%
        {{hash=fb7be81f0574878d688bb03f0abb8502}{%
           family={Bergmeir},
           familyi={B\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod}}}%
        {{hash=d2ea33f311ab7e75395d319cf5cb988d}{%
           family={Bandara},
           familyi={B\bibinitperiod},
           given={Kasun},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{29e798ed628767a2e5b0b45cb594e1c7}
      \strng{fullhash}{29e798ed628767a2e5b0b45cb594e1c7}
      \strng{bibnamehash}{29e798ed628767a2e5b0b45cb594e1c7}
      \strng{authorbibnamehash}{29e798ed628767a2e5b0b45cb594e1c7}
      \strng{authornamehash}{29e798ed628767a2e5b0b45cb594e1c7}
      \strng{authorfullhash}{29e798ed628767a2e5b0b45cb594e1c7}
      \field{sortinit}{8}
      \field{sortinithash}{a231b008ebf0ecbe0b4d96dcc159445f}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recurrent Neural Networks (RNNs) have become competitive forecasting methods, as most notably shown in the winning method of the recent M4 competition. However, established statistical models such as exponential smoothing (ETS) and the autoregressive integrated moving average (ARIMA) gain their popularity not only from their high accuracy, but also because they are suitable for non-expert users in that they are robust, efficient, and automatic. In these areas, RNNs have still a long way to go. We present an extensive empirical study and an open-source software framework of existing RNN architectures for forecasting, and we develop guidelines and best practices for their use. For example, we conclude that RNNs are capable of modelling seasonality directly if the series in the dataset possess homogeneous seasonal patterns; otherwise, we recommend a deseasonalisation step. Comparisons against ETS and ARIMA demonstrate that (semi-) automatic RNN models are not silver bullets, but they are nevertheless competitive alternatives in many situations.}
      \field{issn}{0169-2070}
      \field{journaltitle}{International Journal of Forecasting}
      \field{number}{1}
      \field{title}{Recurrent Neural Networks for Time Series Forecasting: Current status and future directions}
      \field{volume}{37}
      \field{year}{2021}
      \field{pages}{388\bibrangedash 427}
      \range{pages}{40}
      \verb{doi}
      \verb https://doi.org/10.1016/j.ijforecast.2020.06.008
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S0169207020300996
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S0169207020300996
      \endverb
      \keyw{Big data,Forecasting,Best practices,Framework}
    \endentry
    \entry{Tolo}{article}{}
      \name{author}{1}{}{%
        {{hash=ebddf205912a2db30472697f7885a640}{%
           family={TÃ¶lÃ¶},
           familyi={T\bibinitperiod},
           given={Eero},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{ebddf205912a2db30472697f7885a640}
      \strng{fullhash}{ebddf205912a2db30472697f7885a640}
      \strng{bibnamehash}{ebddf205912a2db30472697f7885a640}
      \strng{authorbibnamehash}{ebddf205912a2db30472697f7885a640}
      \strng{authornamehash}{ebddf205912a2db30472697f7885a640}
      \strng{authorfullhash}{ebddf205912a2db30472697f7885a640}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We consider predicting systemic financial crises one to five years ahead using recurrent neural networks. We evaluate the prediction performance with the JÃ³rda-Schularick-Taylor dataset, which includes the crisis dates and annual macroeconomic series of 17 countries over the period 1870âˆ’2016. Previous literature has found that simple neural net architectures are useful and outperform the traditional logistic regression model in predicting systemic financial crises. We show that such predictions can be significantly improved by making use of the Long-Short Term Memory (RNN-LSTM) and the Gated Recurrent Unit (RNN-GRU) neural nets. Behind the success is the recurrent networksâ€™ ability to make more robust predictions from the time series data. The results remain robust after extensive sensitivity analysis.}
      \field{issn}{1572-3089}
      \field{journaltitle}{Journal of Financial Stability}
      \field{title}{Predicting systemic financial crises with recurrent neural networks}
      \field{volume}{49}
      \field{year}{2020}
      \field{pages}{100746}
      \range{pages}{1}
      \verb{doi}
      \verb https://doi.org/10.1016/j.jfs.2020.100746
      \endverb
      \verb{urlraw}
      \verb https://www.sciencedirect.com/science/article/pii/S1572308920300243
      \endverb
      \verb{url}
      \verb https://www.sciencedirect.com/science/article/pii/S1572308920300243
      \endverb
      \keyw{Early warning system,Systemic Banking crises,Neural networks,Validation}
    \endentry
    \entry{Fonville}{article}{}
      \name{author}{1}{}{%
        {{hash=f6cb9e816cf362309b18d3e534b027d7}{%
           family={Fonville},
           familyi={F\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{f6cb9e816cf362309b18d3e534b027d7}
      \strng{fullhash}{f6cb9e816cf362309b18d3e534b027d7}
      \strng{bibnamehash}{f6cb9e816cf362309b18d3e534b027d7}
      \strng{authorbibnamehash}{f6cb9e816cf362309b18d3e534b027d7}
      \strng{authornamehash}{f6cb9e816cf362309b18d3e534b027d7}
      \strng{authorfullhash}{f6cb9e816cf362309b18d3e534b027d7}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Understanding Stock Market Corrections and Crashes (2024)}
      \field{year}{2024}
      \verb{urlraw}
      \verb https://www.covenantwealthadvisors.com/post/understanding-stock-market-corrections-and-crashes?utm_source=chatgpt.com
      \endverb
      \verb{url}
      \verb https://www.covenantwealthadvisors.com/post/understanding-stock-market-corrections-and-crashes?utm_source=chatgpt.com
      \endverb
    \endentry
    \entry{Investo}{article}{}
      \name{author}{1}{}{%
        {{hash=ad06bf06adee8d95fd62057f57acb739}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{ad06bf06adee8d95fd62057f57acb739}
      \strng{fullhash}{ad06bf06adee8d95fd62057f57acb739}
      \strng{bibnamehash}{ad06bf06adee8d95fd62057f57acb739}
      \strng{authorbibnamehash}{ad06bf06adee8d95fd62057f57acb739}
      \strng{authornamehash}{ad06bf06adee8d95fd62057f57acb739}
      \strng{authorfullhash}{ad06bf06adee8d95fd62057f57acb739}
      \field{sortinit}{1}
      \field{sortinithash}{4f6aaa89bab872aa0999fec09ff8e98a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Guide to Stock Market Crash}
      \field{year}{2022}
      \verb{urlraw}
      \verb https://www.investopedia.com/terms/s/stock-market-crash.asp
      \endverb
      \verb{url}
      \verb https://www.investopedia.com/terms/s/stock-market-crash.asp
      \endverb
    \endentry
  \enddatalist
  \missing{lim2021temporal}
  \missing{vaswani2017attention}
  \missing{zhou2021informer}
\endrefsection
\endinput

