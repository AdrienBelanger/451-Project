\documentclass[12pt, letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{tikz} % for timeline
\usepackage{titling} % to make title higher
\usepackage{enumitem}
\usepackage{ragged2e} % justification
\usepackage{comment} % for commenting out multiple lines
\usepackage[
backend=biber,
style=ieee,
sorting=none,
]{biblatex}
\addbibresource{bibliography.bib}



\setlength{\droptitle}{-1.2in}
\pretitle{\vspace{0em}\begin{center}\Large} 
\posttitle{\par\end{center}\vspace{-0.7em}}
\preauthor{\vspace{0em}\begin{center}} 
\postauthor{\par\end{center}\vspace{-0.7em}} 
\predate{\vspace{0em}\begin{center}} 
\postdate{\par\end{center}\vspace{-0.5em}} 


\title{Empirical Review of Models used for Predicting Financial Market Crashes Using Market Data}
\author{\large Project: Literature Review \vspace{0.65em} \\ \normalsize By Ping-Chieh Tu, Adrien BÃ©langer, and Inigo Torres}
\date{November 22$^{\text{nd}}$ 2024}

\begin{document}

\maketitle 

\justifying % justifying our text instead of the annoying list like last time
\begin{comment}
Overall objective to keep in mind:

"In this milestone, the objective is to review the related literature to your proposal. This will better inform your methodology for your project if it involves a new idea, and it is necessary if you are comparing existing methods for a certain domain. It may even lead to a change of proposal, once you learn about existing methods out there. If you are producing a literature survey on a research topic, in this stage, you just provide a "breadth" review, in which you emphasize covering as many related works as possible and providing some preliminary organization without going into much detail."\\

Evaluation Criterias:

- Putting your proposal into context of related literature

- Coverage (are you adequately covering most relevant works)
\end{comment}
\subsection*{Background and Introduction}
The idea of predicting stock market crashes using machine learning is not new.
Multiple papers have approached stock market crash prediction using Machine Learning techniques. 
Traditionally, time series analysis has relied on models like Recurrent Neural Networks (RNNs) and ARIMA. More recently, the introduction of Transformer-based architectures has expanded the range of tools available for this approach \cite{Ahmed, ArunKumar}.These models have been retroactively used with success in Market Crash prediction \cite{Okpeke}. 

Reviews and comparisons of these models, such as this project aims to do, have been made such as \cite{Okpeke}, but a comprehensive empirical review of Time-Series Analysis models on equal footing is lacking in literature. 
This project aims to address this lack, by providing an empirical comparison of the three aforementionned commonly used models in Time-Series Analysis to predict Market Crashes. \cite{Ahmed} \cite{ArunKumar}
We shall use data freely available on the Yahoo finance database, and tag historically factual Market Crashes by hand, as there are only few. We shall use the crashes as listed in this National Bureau of Economic Research's report. \cite{Mishkin}

%\subsection*{Background on Time Series and Financial Market Crashes \textcolor{red}{Adrien}}

% - Define time series in financial analysis -

% - Explain market crashes and justify our definition

%- Review work on financial crash prediction, review different methods

% - Identify gaps in literature that our project adresses and what is new about it

%\subsection*{Methodology}
\subparagraph*{}
 %https://oarjst.com/sites/default/files/OARJST-2024-0095.pdf
    \subsubsection*{ARIMA on predicting market crash \textcolor{red}{Oscar}}
    Time series in stock market are mostly non-stationary. Except for differences in the local level or in trend, all parts of the series behave in a similar way [Box et al. 2015]. Box et al suggested a model called Autoregressive Integrated Moving Average (ARIMA) model which combines an autoregressive model and a moving average model. This model can be used in non-stationary time series to make predictions [M K Ho et al 2021 J. Phys.: Conf. Ser. 1988 012041].
    %https://iopscience.iop.org/article/10.1088/1742-6596/1988/1/012041/pdf
    The ARIMA model ARIMA($p,d,q$) has general form [Box et al. 2015]:
    % http://repo.darmajaya.ac.id/4781/1/Time%20Series%20Analysis_%20Forecasting%20and%20Control%20%28%20PDFDrive%20%29.pdf
    \begin{align*}
        \varphi (B) z_t = \phi (B)\nabla^d z_t = \theta_0 + \theta (B)a_t
    \end{align*}
    where
    \begin{enumerate}[label=\arabic*.]
        \item $\phi(B)$ is the autoregressive part with $p$ degrees,
        \item $\theta (B)$ is the moving average part with $q$ degrees,
        \item $\nabla$ is the integrated (degree of differencing) part with $d$ degrees,
        \item and $\theta_0$ is the constant term.
    \end{enumerate}
    Using ACF (autocorrelation function) and PACF (partial ACF) can help us decide the hyperparameters $p, d, q$ for building our model [Hyndman et al. 2018].
    % https://otexts.com/fpp2/
    \subsubsection*{Reccurent Neural Networks \textcolor{red}{Adrien}}
    %- Overview of Recurrent Neural Networks (RNNs)
    Recurrent Neural Networks are a class of neural network architectures designed to detect patterns in sequential data, such as handwriting, genomes, text, or numerical time series. In time-series, they are used to make sequential predictions based on sequential inputs. \cite{Schmidt} In our context, they usually take the form of Long Term Short Memory (LSTM) cells \cite{Hansika}, which we will use in our project, to mitigate the vanishing gradient problem. They do so by having cells with three gates: An input, output and a forget gate combined with a feedback loop to enhance long-term accuracy. These gates help control how the information flows through the network. \cite{Hansika} They have been used in multiple projects accounting to market Crashes, such as this project led by Tolo et al. \cite{Tolo} It is not well established when RNNs and Arimas outperform one another \cite{Hansika}, this project will take a step into clearing up the most appropriate in the context of Market Crashes prediction.

    %- Review its application in time series analysis in our context
    \subsubsection*{Transformers \textcolor{red}{Inigo}}
Transformers are neural network architectures based on self-attention mechanisms. In other words, they are able to weigh the importance of input elements by computing attention scores between all positions. While transformers were originally developed for natural language processing tasks like machine translation \cite{vaswani2017attention}, they have become popular for time-series forecasting due to their ability to handle long-range dependencies.

Transformers are an ideal choice for predicting trends in volatile time series, as they can capture complex temporal patterns by assigning varying importance to different time steps. In fact, Zhou et al. demonstrated this with the "Informer model," which efficiently handles long sequences and improves trend forecasting accuracy using a "self-attention" mechanism \cite{zhou2021informer}. Moreover, Lim et al. were even able to outperform traditional methods (like ARIMA) by combining the Transformer architecture with recurrent layers \cite{lim2021temporal}. 

What's more, the adaptable mathematical design of transformers makes them a powerful tool for predicting any kind of time series, and financial markets are no exception. Zhen Zeng studied the applicability of Transformers combined with RNNs in trend detection specifically for financial time series in his paper \cite{zeng2023financial}. He concluded that combining these two architectures significantly improved forecasting accuracy for intraday stock price movements of S\&P 500 constituents (S\&P 500 refers to the stock market index that tracks the performance of 500 of the largest publicly traded companies in the United States). Hence, the literature suggests that the self-attention mechanism of Transformers makes them a pertinent choice for financial trend forecasting.

\subsection*{Criterias and Analysis \textcolor{red}{Oscar?}}
A market crash is typically defined as a rapid decline of 20$\%$ or more from a recent peak over a short period\cite{Fonville}\cite{Investo}. This threshold distinguishes a crash from a correction, which is generally a decline of 10$\%$ to less than 20$\%$. The "recent peak" refers to the highest market level before the downturn, and the "short period" often spans days to weeks, though exact durations can vary.

\pagebreak
\printbibliography

% Modify proposal in proposal.tex
%\subsection*{Adapt proposal: \textcolor{red}{Inigo}}
\end{document}
